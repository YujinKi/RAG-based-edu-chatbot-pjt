"""
RAG Service - ê³ ìˆ˜ì¤€ RAG ê¸°ëŠ¥ ì œê³µ
EmbeddingServiceë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬í˜„
"""

from typing import List, Dict, Optional, Any
import google.generativeai as genai
from google.generativeai.types import File
from fastapi import HTTPException

from services.embedding_service import get_embedding_service
from services.pdf_service import get_pdf_loader


class RAGService:
    """
    ê³ ìˆ˜ì¤€ RAG(Retrieval-Augmented Generation) ì„œë¹„ìŠ¤
    ë¬¸ì„œ ì—…ë¡œë“œ, ê²€ìƒ‰, ë‹µë³€ ìƒì„±ì„ í†µí•© ê´€ë¦¬
    """

    def __init__(self):
        """RAGService ì´ˆê¸°í™”"""
        self.embedding_service = get_embedding_service()
        self.pdf_loader = get_pdf_loader()
        self.conversation_history: Dict[str, List[Dict[str, str]]] = {}

    def create_knowledge_base(
        self,
        name: str,
        display_name: Optional[str] = None
    ) -> Dict[str, str]:
        """
        ì§€ì‹ ë² ì´ìŠ¤(Knowledge Base) ìƒì„±

        Args:
            name: ì§€ì‹ ë² ì´ìŠ¤ ì´ë¦„
            display_name: í‘œì‹œ ì´ë¦„

        Returns:
            ìƒì„±ëœ ì§€ì‹ ë² ì´ìŠ¤ ì •ë³´
        """
        try:
            result = self.embedding_service.create_corpus(
                corpus_name=name,
                display_name=display_name
            )

            print(f"âœ… ì§€ì‹ ë² ì´ìŠ¤ ìƒì„±: {name}")

            return result

        except Exception as e:
            print(f"âŒ ì§€ì‹ ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to create knowledge base: {str(e)}"
            )

    def add_document_to_knowledge_base(
        self,
        file_path: str,
        knowledge_base_name: str,
        display_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ì§€ì‹ ë² ì´ìŠ¤ì— ë¬¸ì„œ ì¶”ê°€

        Args:
            file_path: ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ
            knowledge_base_name: ì§€ì‹ ë² ì´ìŠ¤ ì´ë¦„
            display_name: ë¬¸ì„œ í‘œì‹œ ì´ë¦„

        Returns:
            ì¶”ê°€ëœ ë¬¸ì„œ ì •ë³´
        """
        try:
            result = self.embedding_service.upload_file_to_corpus(
                file_path=file_path,
                corpus_name=knowledge_base_name,
                display_name=display_name
            )

            print(f"âœ… ë¬¸ì„œ ì¶”ê°€: {display_name or file_path}")

            return result

        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to add document: {str(e)}"
            )

    def search_knowledge_base(
        self,
        query: str,
        knowledge_base_name: str,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            knowledge_base_name: ê²€ìƒ‰í•  ì§€ì‹ ë² ì´ìŠ¤ ì´ë¦„
            top_k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            results = self.embedding_service.search_in_corpus(
                query=query,
                corpus_name=knowledge_base_name,
                top_k=top_k
            )

            return results

        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to search knowledge base: {str(e)}"
            )

    def ask_question(
        self,
        question: str,
        file_uris: List[str],
        conversation_id: Optional[str] = None,
        model_name: str = "gemini-2.5-flash"
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì— ë‹µë³€ (ê°„ë‹¨í•œ RAG)

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            file_uris: ì°¸ì¡°í•  íŒŒì¼ URI ë¦¬ìŠ¤íŠ¸ (files/xxx í˜•ì‹)
            conversation_id: ëŒ€í™” ID (ëŒ€í™” ì´ë ¥ ê´€ë¦¬ìš©)
            model_name: ì‚¬ìš©í•  Gemini ëª¨ë¸

        Returns:
            ë‹µë³€ ì •ë³´
        """
        try:
            # íŒŒì¼ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
            files = []
            for uri in file_uris:
                file_obj = self.embedding_service.get_file_by_name(uri)
                if file_obj:
                    files.append(file_obj)
                else:
                    print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {uri}")

            if not files:
                raise ValueError("ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

            # ëŒ€í™” ì´ë ¥ ê°€ì ¸ì˜¤ê¸°
            history = []
            if conversation_id and conversation_id in self.conversation_history:
                history = self.conversation_history[conversation_id]

            # ë‹µë³€ ìƒì„±
            result = self.embedding_service.generate_answer_simple(
                query=question,
                files=files,
                model_name=model_name
            )

            # ëŒ€í™” ì´ë ¥ ì €ì¥
            if conversation_id:
                if conversation_id not in self.conversation_history:
                    self.conversation_history[conversation_id] = []

                self.conversation_history[conversation_id].append({
                    "role": "user",
                    "content": question
                })
                self.conversation_history[conversation_id].append({
                    "role": "assistant",
                    "content": result["answer"]
                })

            result["conversation_id"] = conversation_id

            return result

        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ë‹µë³€ ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to answer question: {str(e)}"
            )

    def chat_with_documents(
        self,
        message: str,
        file_uris: List[str],
        conversation_id: str,
        model_name: str = "gemini-2.5-flash"
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ê¸°ë°˜ ì±„íŒ… (ëŒ€í™” ì´ë ¥ ìœ ì§€)

        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            file_uris: ì°¸ì¡°í•  íŒŒì¼ URI ë¦¬ìŠ¤íŠ¸
            conversation_id: ëŒ€í™” ID
            model_name: ì‚¬ìš©í•  Gemini ëª¨ë¸

        Returns:
            ë‹µë³€ ì •ë³´
        """
        try:
            # íŒŒì¼ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
            files = []
            for uri in file_uris:
                file_obj = self.embedding_service.get_file_by_name(uri)
                if file_obj:
                    files.append(file_obj)

            if not files:
                raise ValueError("ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

            # ëŒ€í™” ì´ë ¥ ê°€ì ¸ì˜¤ê¸°
            if conversation_id not in self.conversation_history:
                self.conversation_history[conversation_id] = []

            history = self.conversation_history[conversation_id]

            # ëª¨ë¸ ìƒì„±
            model = genai.GenerativeModel(model_name)

            # ëŒ€í™” ì´ë ¥ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = """ë‹¹ì‹ ì€ ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì—­í• :**
- ë¬¸ì„œì˜ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ì´í•´í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤
- ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì¼ê´€ëœ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ì•Šê³  ì†”ì§íˆ ë§í•©ë‹ˆë‹¤
- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤
"""

            # ëŒ€í™” ì´ë ¥ í¬í•¨
            conversation_text = "\n".join([
                f"{'ì‚¬ìš©ì' if msg['role'] == 'user' else 'AI'}: {msg['content']}"
                for msg in history
            ])

            user_prompt = f"""**ì´ì „ ëŒ€í™”:**
{conversation_text if conversation_text else '(ì²« ëŒ€í™”ì…ë‹ˆë‹¤)'}

**í˜„ì¬ ì§ˆë¬¸:** {message}

ìœ„ ë¬¸ì„œë“¤ê³¼ ëŒ€í™” ë§¥ë½ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

            # ë‹µë³€ ìƒì„±
            content = files + [system_prompt, user_prompt]
            response = model.generate_content(content)

            answer = response.text

            # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
            self.conversation_history[conversation_id].append({
                "role": "user",
                "content": message
            })
            self.conversation_history[conversation_id].append({
                "role": "assistant",
                "content": answer
            })

            print(f"ğŸ’¬ ëŒ€í™” {conversation_id}: {len(self.conversation_history[conversation_id])}ê°œ ë©”ì‹œì§€")

            return {
                "conversation_id": conversation_id,
                "message": message,
                "answer": answer,
                "sources": [f.display_name for f in files],
                "model": model_name,
                "history_length": len(self.conversation_history[conversation_id])
            }

        except Exception as e:
            print(f"âŒ ì±„íŒ… ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to chat with documents: {str(e)}"
            )

    def get_conversation_history(self, conversation_id: str) -> List[Dict[str, str]]:
        """
        ëŒ€í™” ì´ë ¥ ì¡°íšŒ

        Args:
            conversation_id: ëŒ€í™” ID

        Returns:
            ëŒ€í™” ì´ë ¥ ë¦¬ìŠ¤íŠ¸
        """
        return self.conversation_history.get(conversation_id, [])

    def clear_conversation_history(self, conversation_id: str):
        """
        ëŒ€í™” ì´ë ¥ ì‚­ì œ

        Args:
            conversation_id: ëŒ€í™” ID
        """
        if conversation_id in self.conversation_history:
            del self.conversation_history[conversation_id]
            print(f"ğŸ—‘ï¸ ëŒ€í™” ì´ë ¥ ì‚­ì œ: {conversation_id}")

    def generate_quiz_from_document(
        self,
        file_uri: str,
        num_questions: int = 5,
        difficulty: str = "medium",
        model_name: str = "gemini-2.5-flash"
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ë‚´ìš© ê¸°ë°˜ í€´ì¦ˆ ìƒì„±

        Args:
            file_uri: ë¬¸ì„œ íŒŒì¼ URI
            num_questions: ìƒì„±í•  ë¬¸ì œ ìˆ˜
            difficulty: ë‚œì´ë„ (easy, medium, hard)
            model_name: ì‚¬ìš©í•  Gemini ëª¨ë¸

        Returns:
            ìƒì„±ëœ í€´ì¦ˆ ì •ë³´
        """
        try:
            # íŒŒì¼ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
            file_obj = self.embedding_service.get_file_by_name(file_uri)
            if not file_obj:
                raise ValueError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_uri}")

            # ëª¨ë¸ ìƒì„±
            model = genai.GenerativeModel(model_name)

            # í€´ì¦ˆ ìƒì„± í”„ë¡¬í”„íŠ¸
            difficulty_kr = {"easy": "ì‰¬ì›€", "medium": "ë³´í†µ", "hard": "ì–´ë ¤ì›€"}.get(difficulty, "ë³´í†µ")

            prompt = f"""ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ **{num_questions}ê°œì˜ ê°ê´€ì‹ ë¬¸ì œ**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- ë‚œì´ë„: {difficulty_kr}
- ê° ë¬¸ì œëŠ” 4ê°œì˜ ì„ íƒì§€ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤
- ì •ë‹µê³¼ í•´ì„¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”
- ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ë‹¤ë£¨ëŠ” ë¬¸ì œì—¬ì•¼ í•©ë‹ˆë‹¤

**ì¶œë ¥ í˜•ì‹ (JSON):**
```json
{{
    "quiz_title": "í€´ì¦ˆ ì œëª©",
    "total_questions": {num_questions},
    "difficulty": "{difficulty}",
    "questions": [
        {{
            "question_number": 1,
            "question_text": "ë¬¸ì œ ë‚´ìš©",
            "options": [
                "1) ì„ íƒì§€ 1",
                "2) ì„ íƒì§€ 2",
                "3) ì„ íƒì§€ 3",
                "4) ì„ íƒì§€ 4"
            ],
            "correct_answer": "ì •ë‹µ ë²ˆí˜¸ (1~4)",
            "explanation": "í•´ì„¤ ë‚´ìš©"
        }}
    ]
}}
```

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""

            # í€´ì¦ˆ ìƒì„±
            response = model.generate_content([file_obj, prompt])

            # JSON íŒŒì‹±
            import json
            result_text = response.text.strip()

            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if result_text.startswith("```"):
                result_text = result_text.split("```")[1]
                if result_text.startswith("json"):
                    result_text = result_text[4:]

            quiz_data = json.loads(result_text)

            print(f"âœ… í€´ì¦ˆ ìƒì„± ì™„ë£Œ: {num_questions}ê°œ ë¬¸ì œ")

            return {
                "success": True,
                "quiz": quiz_data,
                "source_file": file_obj.display_name
            }

        except Exception as e:
            print(f"âŒ í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to generate quiz: {str(e)}"
            )


# Global RAGService instance (ì‹±ê¸€í†¤ íŒ¨í„´)
_rag_service_instance: Optional[RAGService] = None


def get_rag_service() -> RAGService:
    """
    RAGService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜

    Returns:
        RAGService ì¸ìŠ¤í„´ìŠ¤
    """
    global _rag_service_instance

    if _rag_service_instance is None:
        _rag_service_instance = RAGService()

    return _rag_service_instance
